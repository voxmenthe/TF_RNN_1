{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosave disabled\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from integrated import BasicRNNCell, MultiRNNCell, dynamic_rnn\n",
    "%autosave 0\n",
    "\n",
    "from tensorflow.python.ops import variable_scope as vs\n",
    "from tensorflow.python.util import nest\n",
    "from tensorflow.python.ops import math_ops\n",
    "from tensorflow.python.ops import array_ops\n",
    "from tensorflow.python.ops import init_ops\n",
    "from tensorflow.python.ops import nn_ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def _linear(args, output_size, bias, bias_start=0.0):\n",
    "  \"\"\"Linear map: sum_i(args[i] * W[i]), where W[i] is a variable.\n",
    "  Args:\n",
    "    args: a 2D Tensor or a list of 2D, batch x n, Tensors.\n",
    "    output_size: int, second dimension of W[i].\n",
    "    bias: boolean, whether to add a bias term or not.\n",
    "    bias_start: starting value to initialize the bias; 0 by default.\n",
    "  Returns:\n",
    "    A 2D Tensor with shape [batch x output_size] equal to\n",
    "    sum_i(args[i] * W[i]), where W[i]s are newly created matrices.\n",
    "  Raises:\n",
    "    ValueError: if some of the arguments has unspecified or wrong shape.\n",
    "  \"\"\"\n",
    "  if args is None or (nest.is_sequence(args) and not args):\n",
    "    raise ValueError(\"`args` must be specified\")\n",
    "  if not nest.is_sequence(args):\n",
    "    args = [args]\n",
    "\n",
    "  # Calculate the total size of arguments on dimension 1.\n",
    "  total_arg_size = 0\n",
    "  shapes = [a.get_shape() for a in args]\n",
    "  for shape in shapes:\n",
    "    if shape.ndims != 2:\n",
    "      raise ValueError(\"linear is expecting 2D arguments: %s\" % shapes)\n",
    "    if shape[1].value is None:\n",
    "      raise ValueError(\"linear expects shape[1] to be provided for shape %s, \"\n",
    "                       \"but saw %s\" % (shape, shape[1]))\n",
    "    else:\n",
    "      total_arg_size += shape[1].value\n",
    "\n",
    "  dtype = [a.dtype for a in args][0]\n",
    "\n",
    "  # Now the computation.\n",
    "  scope = vs.get_variable_scope()\n",
    "  with vs.variable_scope(scope) as outer_scope:\n",
    "    weights = vs.get_variable(\n",
    "        \"weights\", [total_arg_size, output_size], dtype=dtype)\n",
    "    \n",
    "    # either one argument or more\n",
    "    if len(args) == 1:\n",
    "      res = math_ops.matmul(args[0], weights)\n",
    "    else:\n",
    "      res = math_ops.matmul(array_ops.concat(args, 1), weights)\n",
    "    \n",
    "    # add biases if they exist\n",
    "    if not bias:\n",
    "      return res\n",
    "    with vs.variable_scope(outer_scope) as inner_scope:\n",
    "      inner_scope.set_partitioner(None)\n",
    "      biases = vs.get_variable(\n",
    "          \"biases\", [output_size],\n",
    "          dtype=dtype,\n",
    "          initializer=init_ops.constant_initializer(bias_start, dtype=dtype))\n",
    "        \n",
    "    return nn_ops.bias_add(res, biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def batch_generator(tensor,batch_size):\n",
    "    i = 0\n",
    "    while i < tensor.shape[0]//batch_size:\n",
    "        yield tensor[i:i+batch_size]\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[      0       1       2 ...,     497     498     499]\n",
      " [    500     501     502 ...,     997     998     999]\n",
      " [   1000    1001    1002 ...,    1497    1498    1499]\n",
      " ..., \n",
      " [4998500 4998501 4998502 ..., 4998997 4998998 4998999]\n",
      " [4999000 4999001 4999002 ..., 4999497 4999498 4999499]\n",
      " [4999500 4999501 4999502 ..., 4999997 4999998 4999999]]\n",
      "\n",
      "[[499999 499998 499997 ..., 499502 499501 499500]\n",
      " [499499 499498 499497 ..., 499002 499001 499000]\n",
      " [498999 498998 498997 ..., 498502 498501 498500]\n",
      " ..., \n",
      " [  1499   1498   1497 ...,   1002   1001   1000]\n",
      " [   999    998    997 ...,    502    501    500]\n",
      " [   499    498    497 ...,      2      1      0]]\n",
      "\n",
      "[[ 1.  1.  1. ...,  1.  1.  1.]\n",
      " [ 1.  1.  1. ...,  1.  1.  1.]\n",
      " [ 1.  1.  1. ...,  1.  1.  1.]\n",
      " ..., \n",
      " [ 1.  1.  1. ...,  1.  1.  1.]\n",
      " [ 1.  1.  1. ...,  1.  1.  1.]\n",
      " [ 1.  1.  1. ...,  1.  1.  1.]]\n",
      "\n",
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
      " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
      " 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n",
      " 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197\n",
      " 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215\n",
      " 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233\n",
      " 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251\n",
      " 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269\n",
      " 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287\n",
      " 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305\n",
      " 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323\n",
      " 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341\n",
      " 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359\n",
      " 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377\n",
      " 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395\n",
      " 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413\n",
      " 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431\n",
      " 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449\n",
      " 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467\n",
      " 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485\n",
      " 486 487 488 489 490 491 492 493 494 495 496 497 498 499]\n"
     ]
    }
   ],
   "source": [
    "num_units = 500\n",
    "n = 10000\n",
    "batch_size = 50\n",
    "X = np.arange(n*num_units).reshape((n,num_units))\n",
    "X_batches = X[:batch_size]\n",
    "#W = np.arange(9)[::-1].reshape((3,3))\n",
    "W = np.arange(num_units**2*2)[::-1].reshape((num_units*2,num_units))\n",
    "#h = np.ones(n*num_units).reshape((n,num_units)) # adding second dimension\n",
    "h = np.ones(batch_size*num_units).reshape((batch_size,num_units)) # adding second dimension\n",
    "B = np.arange(num_units)\n",
    "print(X)\n",
    "print()\n",
    "print(W)\n",
    "print()\n",
    "print(h)\n",
    "print()\n",
    "print(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0,     1,     2, ...,   497,   498,   499],\n",
       "       [  500,   501,   502, ...,   997,   998,   999],\n",
       "       [ 1000,  1001,  1002, ...,  1497,  1498,  1499],\n",
       "       ..., \n",
       "       [23500, 23501, 23502, ..., 23997, 23998, 23999],\n",
       "       [24000, 24001, 24002, ..., 24497, 24498, 24499],\n",
       "       [24500, 24501, 24502, ..., 24997, 24998, 24999]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "scope = vs.get_variable_scope()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gen = batch_generator(X,batch_size)\n",
    "x = next(gen)\n",
    "inputs = tf.Variable(initial_value=x,dtype=tf.float32)\n",
    "hidden_state = tf.Variable(initial_value=h,dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  1.,  1., ...,  1.,  1.,  1.],\n",
       "       [ 1.,  1.,  1., ...,  1.,  1.,  1.],\n",
       "       [ 1.,  1.,  1., ...,  1.,  1.,  1.],\n",
       "       ..., \n",
       "       [ 1.,  1.,  1., ...,  1.,  1.,  1.],\n",
       "       [ 1.,  1.,  1., ...,  1.,  1.,  1.],\n",
       "       [ 1.,  1.,  1., ...,  1.,  1.,  1.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "weights = []\n",
    "biases = []\n",
    "\n",
    "with vs.variable_scope(scope) as outer_scope:\n",
    "    # now becomes variable type which is a pointer to something inside the graph\n",
    "    weights = tf.get_variable(\"weights\",[num_units*2,num_units],dtype=tf.float32)\n",
    "    biases = tf.get_variable(\"biases\",[num_units],dtype=tf.float32)\n",
    "\n",
    "# now that we've set reuse no more variable creation\n",
    "scope.reuse_variables()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer()\n",
    "    \n",
    "    out = sess.run(_linear([inputs,hidden_state], num_units, bias=True),feed_dict = {\n",
    "        weights: W,\n",
    "        inputs: x,\n",
    "        biases: B,\n",
    "        hidden_state: h\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  4.16666337e+10,   4.16665108e+10,   4.16663634e+10, ...,\n",
       "          4.16043827e+10,   4.16042516e+10,   4.16041206e+10],\n",
       "       [  1.35478886e+11,   1.35478477e+11,   1.35478100e+11, ...,\n",
       "          1.35292379e+11,   1.35292027e+11,   1.35291650e+11],\n",
       "       [  2.29291114e+11,   2.29290557e+11,   2.29289902e+11, ...,\n",
       "          2.28980326e+11,   2.28979704e+11,   2.28979081e+11],\n",
       "       ..., \n",
       "       [  4.45084651e+12,   4.45083340e+12,   4.45082029e+12, ...,\n",
       "          4.44494407e+12,   4.44493149e+12,   4.44491891e+12],\n",
       "       [  4.54465788e+12,   4.54464582e+12,   4.54463324e+12, ...,\n",
       "          4.53863172e+12,   4.53861966e+12,   4.53860812e+12],\n",
       "       [  4.63847083e+12,   4.63845720e+12,   4.63844304e+12, ...,\n",
       "          4.63231831e+12,   4.63230363e+12,   4.63229315e+12]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer()\n",
    "    weights = vs.get_variable(\n",
    "      \"weights\", [10, 10], dtype=tf.float32)\n",
    "    out = sess.run(output,feed_dict = {\n",
    "        weights: b,\n",
    "        inputs: a\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  4.16666337e+10,   4.16665108e+10,   4.16663634e+10, ...,\n",
       "          4.16043827e+10,   4.16042516e+10,   4.16041206e+10],\n",
       "       [  1.35478886e+11,   1.35478477e+11,   1.35478100e+11, ...,\n",
       "          1.35292379e+11,   1.35292027e+11,   1.35291650e+11],\n",
       "       [  2.29291114e+11,   2.29290557e+11,   2.29289902e+11, ...,\n",
       "          2.28980326e+11,   2.28979704e+11,   2.28979081e+11],\n",
       "       ..., \n",
       "       [  4.45084651e+12,   4.45083340e+12,   4.45082029e+12, ...,\n",
       "          4.44494407e+12,   4.44493149e+12,   4.44491891e+12],\n",
       "       [  4.54465788e+12,   4.54464582e+12,   4.54463324e+12, ...,\n",
       "          4.53863172e+12,   4.53861966e+12,   4.53860812e+12],\n",
       "       [  4.63847083e+12,   4.63845720e+12,   4.63844304e+12, ...,\n",
       "          4.63231831e+12,   4.63230363e+12,   4.63229315e+12]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
