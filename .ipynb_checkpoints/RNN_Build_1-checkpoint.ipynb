{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosave disabled\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from integrated import BasicRNNCell, MultiRNNCell, dynamic_rnn\n",
    "#from core_rnn_cell_impl import BasicRNNCell, GRUCell, MultiRNNCell\n",
    "#from rnn import dynamic_rnn\n",
    "%autosave 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BasicRNN:\n",
      "Number of state outputs: 3\n",
      "(<tf.Tensor 'rnn/while/Exit_2:0' shape=(?, 100) dtype=float32>, <tf.Tensor 'rnn/while/Exit_3:0' shape=(?, 100) dtype=float32>, <tf.Tensor 'rnn/while/Exit_4:0' shape=(?, 100) dtype=float32>)\n"
     ]
    }
   ],
   "source": [
    "i = np.zeros([10, 10, 10], dtype=np.float32)\n",
    "num_layers = 3\n",
    "\n",
    "g = tf.Graph()\n",
    "with g.as_default():\n",
    "    cell_base = BasicRNNCell(100)\n",
    "    cell = MultiRNNCell([BasicRNNCell(100) for _ in range(num_layers)])\n",
    "    output, state = dynamic_rnn(cell, i, dtype=tf.float32)\n",
    "    print('\\nBasicRNN:\\nNumber of state outputs: {}\\n{}'.format(len(state), state))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "g = tf.Graph()\n",
    "with g.as_default():\n",
    "    cell_base = GRUCell(100)\n",
    "    cell = tf.contrib.rnn.MultiRNNCell([tf.contrib.rnn.GRUCell(100) for _ in range(num_layers)])\n",
    "    output, state = tf.nn.dynamic_rnn(cell, i, dtype=tf.float32)\n",
    "    print('\\nGRU:\\nNumber of state outputs: {}\\n{}'.format(len(state), state))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "g = tf.Graph()\n",
    "with g.as_default():\n",
    "    cell_base = tf.contrib.rnn.BasicLSTMCell(100)\n",
    "    cell = tf.contrib.rnn.MultiRNNCell([tf.contrib.rnn.BasicLSTMCell(100) for _ in range(num_layers)])\n",
    "    output, state = tf.nn.dynamic_rnn(cell, i, dtype=tf.float32)\n",
    "    print('\\nLSTM:\\nNumber of state outputs: {}\\n{}'.format(len(state), state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.ops import variable_scope as vs\n",
    "from tensorflow.python.util import nest\n",
    "from tensorflow.python.ops import math_ops\n",
    "from tensorflow.python.ops import array_ops\n",
    "from tensorflow.python.ops import init_ops\n",
    "\n",
    "\n",
    "def linear2(args, output_size, bias, bias_start=0.0):\n",
    "  \"\"\"Linear map: sum_i(args[i] * W[i]), where W[i] is a variable.\n",
    "  Args:\n",
    "    args: a 2D Tensor or a list of 2D, batch x n, Tensors.\n",
    "    output_size: int, second dimension of W[i].\n",
    "    bias: boolean, whether to add a bias term or not.\n",
    "    bias_start: starting value to initialize the bias; 0 by default.\n",
    "  Returns:\n",
    "    A 2D Tensor with shape [batch x output_size] equal to\n",
    "    sum_i(args[i] * W[i]), where W[i]s are newly created matrices.\n",
    "  Raises:\n",
    "    ValueError: if some of the arguments has unspecified or wrong shape.\n",
    "  \"\"\"\n",
    "  if args is None or (nest.is_sequence(args) and not args):\n",
    "    raise ValueError(\"`args` must be specified\")\n",
    "  if not nest.is_sequence(args):\n",
    "    args = [args]\n",
    "\n",
    "  # Calculate the total size of arguments on dimension 1.\n",
    "  total_arg_size = 0\n",
    "  shapes = [a.get_shape() for a in args]\n",
    "  for shape in shapes:\n",
    "    if shape.ndims != 2:\n",
    "      raise ValueError(\"linear is expecting 2D arguments: %s\" % shapes)\n",
    "    if shape[1].value is None:\n",
    "      raise ValueError(\"linear expects shape[1] to be provided for shape %s, \"\n",
    "                       \"but saw %s\" % (shape, shape[1]))\n",
    "    else:\n",
    "      total_arg_size += shape[1].value\n",
    "\n",
    "  dtype = [a.dtype for a in args][0]\n",
    "\n",
    "  # Now the computation.\n",
    "  weights = vs.get_variable(\n",
    "      \"weights\", [total_arg_size, output_size], dtype=dtype)\n",
    "  if len(args) == 1:\n",
    "    res = math_ops.matmul(args[0], weights)\n",
    "  else:\n",
    "    res = math_ops.matmul(array_ops.concat(args, 1), weights)\n",
    "  if not bias:\n",
    "    return res\n",
    "  biases = vs.get_variable(\n",
    "      \"biases\", [output_size],\n",
    "      dtype=dtype,\n",
    "      initializer=init_ops.constant_initializer(bias_start, dtype=dtype))\n",
    "  return nn_ops.bias_add(res, biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.ops import variable_scope as vs\n",
    "from tensorflow.python.util import nest\n",
    "from tensorflow.python.ops import math_ops\n",
    "from tensorflow.python.ops import array_ops\n",
    "from tensorflow.python.ops import init_ops\n",
    "from tensorflow.python.ops import nn_ops\n",
    "\n",
    "\n",
    "def linear3(args, output_size, bias, bias_start=0.0):\n",
    "  \"\"\"Linear map: sum_i(args[i] * W[i]), where W[i] is a variable.\n",
    "  Args:\n",
    "    args: a 2D Tensor or a list of 2D, batch x n, Tensors.\n",
    "    output_size: int, second dimension of W[i].\n",
    "    bias: boolean, whether to add a bias term or not.\n",
    "    bias_start: starting value to initialize the bias; 0 by default.\n",
    "  Returns:\n",
    "    A 2D Tensor with shape [batch x output_size] equal to\n",
    "    sum_i(args[i] * W[i]), where W[i]s are newly created matrices.\n",
    "  Raises:\n",
    "    ValueError: if some of the arguments has unspecified or wrong shape.\n",
    "  \"\"\"\n",
    "  if args is None or (nest.is_sequence(args) and not args):\n",
    "    raise ValueError(\"`args` must be specified\")\n",
    "  if not nest.is_sequence(args):\n",
    "    args = [args]\n",
    "\n",
    "  # Calculate the total size of arguments on dimension 1.\n",
    "  total_arg_size = 0\n",
    "  shapes = [a.get_shape() for a in args]\n",
    "  for shape in shapes:\n",
    "    if shape.ndims != 2:\n",
    "      raise ValueError(\"linear is expecting 2D arguments: %s\" % shapes)\n",
    "    if shape[1].value is None:\n",
    "      raise ValueError(\"linear expects shape[1] to be provided for shape %s, \"\n",
    "                       \"but saw %s\" % (shape, shape[1]))\n",
    "    else:\n",
    "      total_arg_size += shape[1].value\n",
    "\n",
    "  dtype = [a.dtype for a in args][0]\n",
    "\n",
    "  # Now the computation.\n",
    "  scope = vs.get_variable_scope()\n",
    "  with vs.variable_scope(scope) as outer_scope:\n",
    "    weights = vs.get_variable(\n",
    "        \"weights\", [total_arg_size, output_size], dtype=dtype)\n",
    "    \n",
    "    # either one argument or more\n",
    "    if len(args) == 1:\n",
    "      res = math_ops.matmul(args[0], weights)\n",
    "    else:\n",
    "      res = math_ops.matmul(array_ops.concat(args, 1), weights)\n",
    "    \n",
    "    # add biases if they exist\n",
    "    if not bias:\n",
    "      return res\n",
    "    with vs.variable_scope(outer_scope) as inner_scope:\n",
    "      inner_scope.set_partitioner(None)\n",
    "      biases = vs.get_variable(\n",
    "          \"biases\", [output_size],\n",
    "          dtype=dtype,\n",
    "          initializer=init_ops.constant_initializer(bias_start, dtype=dtype))\n",
    "        \n",
    "    return nn_ops.bias_add(res, biases)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "tf.reset_default_graph()\n",
    "scope = vs.get_variable_scope()\n",
    "num_units = 10\n",
    "inputs = tf.zeros((10,10),dtype=tf.float32)\n",
    "scope = vs.get_variable_scope()\n",
    "with vs.variable_scope(scope) as outer_scope:\n",
    "  weights = tf.get_variable(\"weights\",[10,10],dtype=tf.float32)\n",
    "# biases = tf.Variable(tf.zeros((10,10)),name=\"biases\")\n",
    "#  output = new_state = act(W * input + U * state + B).\n",
    "#output = linear2([inputs, state], num_units, True))\n",
    "scope.reuse_variables()\n",
    "output = linear3(inputs, num_units, None)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer()\n",
    "    weights = vs.get_variable(\n",
    "      \"weights\", [10, 10], dtype=tf.float32)\n",
    "    out = sess.run(output,feed_dict = {\n",
    "        weights: np.zeros((10,10)),\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#at = tf.constant(a)\n",
    "#bt = tf.constant(b)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "scope = vs.get_variable_scope()\n",
    "\n",
    "num_units = 10\n",
    "inputs = tf.zeros((10,10),dtype=tf.float32)\n",
    "\n",
    "with vs.variable_scope(scope) as outer_scope:\n",
    "  weights = tf.get_variable(\"weights\",[10,10],dtype=tf.float32)\n",
    "\n",
    "# biases = tf.Variable(tf.zeros((10,10)),name=\"biases\")\n",
    "#  output = new_state = act(W * input + U * state + B).\n",
    "#output = linear2([inputs, state], num_units, True))\n",
    "scope.reuse_variables()\n",
    "output = linear3(inputs, num_units, None)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer()\n",
    "#     scope = vs.get_variable_scope()\n",
    "#     with vs.variable_scope(scope) as outer_scope:\n",
    "#         weights = tf.get_variable(\"weights\",[10,10],dtype=tf.float32)\n",
    "#     scope.reuse_variables()\n",
    "    weights = vs.get_variable(\n",
    "      \"weights\", [10, 10], dtype=tf.float32)\n",
    "\n",
    "#     out = sess.run(linear3(inputs, num_units, None),feed_dict = {\n",
    "#         weights: b,\n",
    "#         inputs: a\n",
    "#     })\n",
    "    \n",
    "    out = sess.run(output,feed_dict = {\n",
    "        weights: b,\n",
    "        inputs: a\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 2]\n",
      " [3 4 5]\n",
      " [6 7 8]]\n",
      "\n",
      "[[17 16 15]\n",
      " [14 13 12]\n",
      " [11 10  9]\n",
      " [ 8  7  6]\n",
      " [ 5  4  3]\n",
      " [ 2  1  0]]\n",
      "\n",
      "[[ 1.  1.  1.]\n",
      " [ 1.  1.  1.]\n",
      " [ 1.  1.  1.]]\n",
      "\n",
      "[0 1 2]\n"
     ]
    }
   ],
   "source": [
    "x = np.arange(9).reshape((3,3))\n",
    "#W = np.arange(9)[::-1].reshape((3,3))\n",
    "W = np.arange(18)[::-1].reshape((6,3))\n",
    "h = np.ones(9).reshape((3,3)) # adding second dimension\n",
    "B = np.arange(3)\n",
    "print(x)\n",
    "print()\n",
    "print(W)\n",
    "print()\n",
    "print(h)\n",
    "print()\n",
    "print(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (3,3) and (6,3) not aligned: 3 (dim 1) != 6 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-77-e066dcc63d20>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: shapes (3,3) and (6,3) not aligned: 3 (dim 1) != 6 (dim 0)"
     ]
    }
   ],
   "source": [
    "np.matmul(x,W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "scope = vs.get_variable_scope()\n",
    "\n",
    "num_units = 3\n",
    "inputs = tf.zeros((num_units,num_units),dtype=tf.float32)\n",
    "\n",
    "hidden_state = tf.Variable(initial_value=bb,dtype=tf.float32)\n",
    "weights = []\n",
    "biases = []\n",
    "\n",
    "with vs.variable_scope(scope) as outer_scope:\n",
    "    # now becomes variable type which is a pointer to something inside the graph\n",
    "    weights = tf.get_variable(\"weights\",[num_units*2,num_units],dtype=tf.float32)\n",
    "    biases = tf.get_variable(\"biases\",[num_units],dtype=tf.float32)\n",
    "\n",
    "# now that we've set reuse no more variable creation\n",
    "scope.reuse_variables()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer()\n",
    "\n",
    "    out = sess.run(linear3([inputs,hidden_state], num_units, bias=True),feed_dict = {\n",
    "        weights: W,\n",
    "        inputs: x,\n",
    "        biases: B,\n",
    "        hidden_state: h\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  51.,   46.,   41.],\n",
       "       [ 177.,  163.,  149.],\n",
       "       [ 303.,  280.,  257.]], dtype=float32)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer()\n",
    "    weights = vs.get_variable(\n",
    "      \"weights\", [10, 10], dtype=tf.float32)\n",
    "    out = sess.run(output,feed_dict = {\n",
    "        weights: b,\n",
    "        inputs: a\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1605.,   1560.,   1515.,   1470.,   1425.,   1380.,   1335.,\n",
       "          1290.,   1245.,   1200.],\n",
       "       [  7005.,   6860.,   6715.,   6570.,   6425.,   6280.,   6135.,\n",
       "          5990.,   5845.,   5700.],\n",
       "       [ 12405.,  12160.,  11915.,  11670.,  11425.,  11180.,  10935.,\n",
       "         10690.,  10445.,  10200.],\n",
       "       [ 17805.,  17460.,  17115.,  16770.,  16425.,  16080.,  15735.,\n",
       "         15390.,  15045.,  14700.],\n",
       "       [ 23205.,  22760.,  22315.,  21870.,  21425.,  20980.,  20535.,\n",
       "         20090.,  19645.,  19200.],\n",
       "       [ 28605.,  28060.,  27515.,  26970.,  26425.,  25880.,  25335.,\n",
       "         24790.,  24245.,  23700.],\n",
       "       [ 34005.,  33360.,  32715.,  32070.,  31425.,  30780.,  30135.,\n",
       "         29490.,  28845.,  28200.],\n",
       "       [ 39405.,  38660.,  37915.,  37170.,  36425.,  35680.,  34935.,\n",
       "         34190.,  33445.,  32700.],\n",
       "       [ 44805.,  43960.,  43115.,  42270.,  41425.,  40580.,  39735.,\n",
       "         38890.,  38045.,  37200.],\n",
       "       [ 50205.,  49260.,  48315.,  47370.,  46425.,  45480.,  44535.,\n",
       "         43590.,  42645.,  41700.]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'get_shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-b7a43ae72a21>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     weights = vs.get_variable(\n\u001b[1;32m      4\u001b[0m       \"weights\", [10, 10], dtype=tf.float32)\n\u001b[0;32m----> 5\u001b[0;31m     out = sess.run(linear3(a,10,None),feed_dict = {\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mweights\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     })\n",
      "\u001b[0;32m<ipython-input-4-46e2dba52e0c>\u001b[0m in \u001b[0;36mlinear3\u001b[0;34m(args, output_size, bias, bias_start)\u001b[0m\n\u001b[1;32m     25\u001b[0m   \u001b[0;31m# Calculate the total size of arguments on dimension 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m   \u001b[0mtotal_arg_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m   \u001b[0mshapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mshapes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndims\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-46e2dba52e0c>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     25\u001b[0m   \u001b[0;31m# Calculate the total size of arguments on dimension 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m   \u001b[0mtotal_arg_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m   \u001b[0mshapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mshapes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndims\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'get_shape'"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer()\n",
    "    weights = vs.get_variable(\n",
    "      \"weights\", [10, 10], dtype=tf.float32)\n",
    "    out = sess.run(linear3(a,10,None),feed_dict = {\n",
    "        weights: b\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sess1 = tf.Session()\n",
    "print(sess1.run(array_ops.concat((a,b),axis=0)))\n",
    "print(sess1.run(array_ops.concat((a,b),axis=1)))\n",
    "sess1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
