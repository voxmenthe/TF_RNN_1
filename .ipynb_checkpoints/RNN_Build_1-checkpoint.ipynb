{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosave disabled\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from integrated import BasicRNNCell, MultiRNNCell, dynamic_rnn\n",
    "#from core_rnn_cell_impl import BasicRNNCell, GRUCell, MultiRNNCell\n",
    "#from rnn import dynamic_rnn\n",
    "%autosave 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BasicRNN:\n",
      "Number of state outputs: 3\n",
      "(<tf.Tensor 'rnn/while/Exit_2:0' shape=(?, 100) dtype=float32>, <tf.Tensor 'rnn/while/Exit_3:0' shape=(?, 100) dtype=float32>, <tf.Tensor 'rnn/while/Exit_4:0' shape=(?, 100) dtype=float32>)\n"
     ]
    }
   ],
   "source": [
    "i = np.zeros([10, 10, 10], dtype=np.float32)\n",
    "num_layers = 3\n",
    "\n",
    "g = tf.Graph()\n",
    "with g.as_default():\n",
    "    cell_base = BasicRNNCell(100)\n",
    "    cell = MultiRNNCell([BasicRNNCell(100) for _ in range(num_layers)])\n",
    "    output, state = dynamic_rnn(cell, i, dtype=tf.float32)\n",
    "    print('\\nBasicRNN:\\nNumber of state outputs: {}\\n{}'.format(len(state), state))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "g = tf.Graph()\n",
    "with g.as_default():\n",
    "    cell_base = GRUCell(100)\n",
    "    cell = tf.contrib.rnn.MultiRNNCell([tf.contrib.rnn.GRUCell(100) for _ in range(num_layers)])\n",
    "    output, state = tf.nn.dynamic_rnn(cell, i, dtype=tf.float32)\n",
    "    print('\\nGRU:\\nNumber of state outputs: {}\\n{}'.format(len(state), state))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "g = tf.Graph()\n",
    "with g.as_default():\n",
    "    cell_base = tf.contrib.rnn.BasicLSTMCell(100)\n",
    "    cell = tf.contrib.rnn.MultiRNNCell([tf.contrib.rnn.BasicLSTMCell(100) for _ in range(num_layers)])\n",
    "    output, state = tf.nn.dynamic_rnn(cell, i, dtype=tf.float32)\n",
    "    print('\\nLSTM:\\nNumber of state outputs: {}\\n{}'.format(len(state), state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.ops import variable_scope as vs\n",
    "from tensorflow.python.util import nest\n",
    "from tensorflow.python.ops import math_ops\n",
    "\n",
    "def linear2(args, output_size, bias, bias_start=0.0):\n",
    "  \"\"\"Linear map: sum_i(args[i] * W[i]), where W[i] is a variable.\n",
    "  Args:\n",
    "    args: a 2D Tensor or a list of 2D, batch x n, Tensors.\n",
    "    output_size: int, second dimension of W[i].\n",
    "    bias: boolean, whether to add a bias term or not.\n",
    "    bias_start: starting value to initialize the bias; 0 by default.\n",
    "  Returns:\n",
    "    A 2D Tensor with shape [batch x output_size] equal to\n",
    "    sum_i(args[i] * W[i]), where W[i]s are newly created matrices.\n",
    "  Raises:\n",
    "    ValueError: if some of the arguments has unspecified or wrong shape.\n",
    "  \"\"\"\n",
    "  if args is None or (nest.is_sequence(args) and not args):\n",
    "    raise ValueError(\"`args` must be specified\")\n",
    "  if not nest.is_sequence(args):\n",
    "    args = [args]\n",
    "\n",
    "  # Calculate the total size of arguments on dimension 1.\n",
    "  total_arg_size = 0\n",
    "  shapes = [a.get_shape() for a in args]\n",
    "  for shape in shapes:\n",
    "    if shape.ndims != 2:\n",
    "      raise ValueError(\"linear is expecting 2D arguments: %s\" % shapes)\n",
    "    if shape[1].value is None:\n",
    "      raise ValueError(\"linear expects shape[1] to be provided for shape %s, \"\n",
    "                       \"but saw %s\" % (shape, shape[1]))\n",
    "    else:\n",
    "      total_arg_size += shape[1].value\n",
    "\n",
    "  dtype = [a.dtype for a in args][0]\n",
    "\n",
    "  # Now the computation.\n",
    "  weights = vs.get_variable(\n",
    "      \"weights\", [total_arg_size, output_size], dtype=dtype)\n",
    "  if len(args) == 1:\n",
    "    res = math_ops.matmul(args[0], weights)\n",
    "  else:\n",
    "    res = math_ops.matmul(array_ops.concat(args, 1), weights)\n",
    "  if not bias:\n",
    "    return res\n",
    "  biases = vs.get_variable(\n",
    "      \"biases\", [output_size],\n",
    "      dtype=dtype,\n",
    "      initializer=init_ops.constant_initializer(bias_start, dtype=dtype))\n",
    "  return nn_ops.bias_add(res, biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def linear3(args, output_size, bias, bias_start=0.0):\n",
    "  \"\"\"Linear map: sum_i(args[i] * W[i]), where W[i] is a variable.\n",
    "  Args:\n",
    "    args: a 2D Tensor or a list of 2D, batch x n, Tensors.\n",
    "    output_size: int, second dimension of W[i].\n",
    "    bias: boolean, whether to add a bias term or not.\n",
    "    bias_start: starting value to initialize the bias; 0 by default.\n",
    "  Returns:\n",
    "    A 2D Tensor with shape [batch x output_size] equal to\n",
    "    sum_i(args[i] * W[i]), where W[i]s are newly created matrices.\n",
    "  Raises:\n",
    "    ValueError: if some of the arguments has unspecified or wrong shape.\n",
    "  \"\"\"\n",
    "  if args is None or (nest.is_sequence(args) and not args):\n",
    "    raise ValueError(\"`args` must be specified\")\n",
    "  if not nest.is_sequence(args):\n",
    "    args = [args]\n",
    "\n",
    "  # Calculate the total size of arguments on dimension 1.\n",
    "  total_arg_size = 0\n",
    "  shapes = [a.get_shape() for a in args]\n",
    "  for shape in shapes:\n",
    "    if shape.ndims != 2:\n",
    "      raise ValueError(\"linear is expecting 2D arguments: %s\" % shapes)\n",
    "    if shape[1].value is None:\n",
    "      raise ValueError(\"linear expects shape[1] to be provided for shape %s, \"\n",
    "                       \"but saw %s\" % (shape, shape[1]))\n",
    "    else:\n",
    "      total_arg_size += shape[1].value\n",
    "\n",
    "  dtype = [a.dtype for a in args][0]\n",
    "\n",
    "  # Now the computation.\n",
    "  scope = vs.get_variable_scope()\n",
    "  with vs.variable_scope(scope) as outer_scope:\n",
    "    weights = vs.get_variable(\n",
    "        \"weights\", [total_arg_size, output_size], dtype=dtype)\n",
    "    if len(args) == 1:\n",
    "      res = math_ops.matmul(args[0], weights)\n",
    "    else:\n",
    "      res = math_ops.matmul(array_ops.concat(args, 1), weights)\n",
    "    if not bias:\n",
    "      return res\n",
    "    with vs.variable_scope(outer_scope) as inner_scope:\n",
    "      inner_scope.set_partitioner(None)\n",
    "      biases = vs.get_variable(\n",
    "          \"biases\", [output_size],\n",
    "          dtype=dtype,\n",
    "          initializer=init_ops.constant_initializer(bias_start, dtype=dtype))\n",
    "    return nn_ops.bias_add(res, biases)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "scope = vs.get_variable_scope()\n",
    "num_units = 10\n",
    "inputs = tf.zeros((10,10),dtype=tf.float32)\n",
    "scope = vs.get_variable_scope()\n",
    "with vs.variable_scope(scope) as outer_scope:\n",
    "  weights = tf.get_variable(\"weights\",[10,10],dtype=tf.float32)\n",
    "# biases = tf.Variable(tf.zeros((10,10)),name=\"biases\")\n",
    "#  output = new_state = act(W * input + U * state + B).\n",
    "#output = linear2([inputs, state], num_units, True))\n",
    "scope.reuse_variables()\n",
    "output = linear3(inputs, num_units, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'MatMul:0' shape=(10, 100) dtype=float32>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer()\n",
    "    weights = vs.get_variable(\n",
    "      \"weights\", [10, 10], dtype=tf.float32)\n",
    "    out = sess.run(output,feed_dict = {\n",
    "        weights: np.zeros((10,10)) \n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]], dtype=float32)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
