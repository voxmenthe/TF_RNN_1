{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosave disabled\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%autosave 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For every layer in the network we need a hidden state and a cell state. Typically, the input to the next LSTM-layer will be the previous state for that particular layer as well as the hidden activations of the \"lower\" or previous layer.\n",
    "\n",
    "We could continue to store the states for each layer in many LSTMTuples, but that would require a lot of overhead. You can only input data to the placeholder through the `feed_dict` as Python lists or Numpy arrays anyway (not LSTMTuples) so why not save the whole state for the network in one big tensor? So we want to replace `_current_cell_state` and `current_hidden_state` with:\n",
    "\n",
    "`_current_state = np.zeros((num_layers, 2, batch_size, state_size))`\n",
    "\n",
    "We also have to declare the new setting `num_layers=3` in the beginning of the file but can choose any number of layers. The `2` refers to the two states: cell_state and hidden_state. So for each layer and each sample in a batch, we have both a cell state and a hidden state vector with the size `state_size`.\n",
    "\n",
    "Now in the sess.run change the state tuple back to the original statement since now stored in a single tensor. We also change the placeholder definitions back to a single placeholder containing the whole state:\n",
    "\n",
    "`init_state = tf.placeholder(tf.float32, [num_layers, 2, batch_size, state_size])`\n",
    "\n",
    "Now since the Tensorflow Multilayer-LSTM-API accepts the state as a tuple of LSTMTuples, we need to unpack the states into this structure. For each layer in the state we then create an LSTMTuple and put thes in a tuple. Add this after the init_state placeholder:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "state_per_layer_list = tf.unstack(init_state, axis=0)\n",
    "rnn_tuple_state = tuple(\n",
    "    [tf.contrib.rnn.LSTMStateTuple(state_per_layer_list[idx][0], state_per_layer_list[idx][1])\n",
    "    for idx in range(num_layers)]\n",
    "    )"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The forward pass should be changed to:\n",
    "\n",
    "# Forward passes\n",
    "#cell = tf.contrib.rnn.LSTMCell(state_size, state_is_tuple=True)\n",
    "cell = tf.contrib.rnn.MultiRNNCell( [tf.contrib.rnn.LSTMCell(state_size, state_is_tuple=True) \n",
    "                                    for _ in range(num_layers)], \n",
    "                                    state_is_tuple=True)\n",
    "states_series, current_state = tf.nn.dynamic_rnn(cell, inputs_series, initial_state=rnn_tuple_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The multi-layered LSTM is created by first making a single LSTMCell, and then duplicating this cell in an array, supplying it to the MultiRNNCell API call. The forward pass uses the usual tf.nn.static_rnn or dynamic_rnn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-4-35df54c6f2b0>:80: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fbf4c430d30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data, epoch 0\n",
      "Step 0 Batch loss 0.693417\n",
      "New data, epoch 1\n",
      "Step 0 Batch loss 0.687998\n",
      "New data, epoch 2\n",
      "Step 0 Batch loss 0.685065\n",
      "New data, epoch 3\n",
      "Step 0 Batch loss 0.594729\n",
      "New data, epoch 4\n",
      "Step 0 Batch loss 0.644176\n",
      "New data, epoch 5\n",
      "Step 0 Batch loss 0.616494\n",
      "New data, epoch 6\n",
      "Step 0 Batch loss 0.532482\n",
      "New data, epoch 7\n",
      "Step 0 Batch loss 0.460148\n",
      "New data, epoch 8\n",
      "Step 0 Batch loss 0.255661\n",
      "New data, epoch 9\n",
      "Step 0 Batch loss 0.649825\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fbf4af30518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "num_epochs = 10 # previously 100\n",
    "total_series_length = 5000 # previously 50000\n",
    "truncated_backprop_length = 15\n",
    "state_size = 4\n",
    "num_classes = 2\n",
    "echo_step = 3\n",
    "batch_size = 5\n",
    "num_batches = total_series_length//batch_size//truncated_backprop_length\n",
    "num_layers = 3\n",
    "\n",
    "def generateData():\n",
    "    x = np.array(np.random.choice(2, total_series_length, p=[0.5, 0.5]))\n",
    "    y = np.roll(x, echo_step)\n",
    "    y[0:echo_step] = 0\n",
    "\n",
    "    x = x.reshape((batch_size, -1))  # The first index changing slowest, subseries as rows\n",
    "    y = y.reshape((batch_size, -1))\n",
    "\n",
    "    return (x, y)\n",
    "\n",
    "batchX_placeholder = tf.placeholder(tf.float32, [batch_size, truncated_backprop_length])\n",
    "batchY_placeholder = tf.placeholder(tf.int32, [batch_size, truncated_backprop_length])\n",
    "\n",
    "init_state = tf.placeholder(tf.float32, [num_layers, 2, batch_size, state_size])\n",
    "\n",
    "state_per_layer_list = tf.unstack(init_state, axis=0)\n",
    "rnn_tuple_state = tuple(\n",
    "    [tf.contrib.rnn.LSTMStateTuple(state_per_layer_list[idx][0], state_per_layer_list[idx][1])\n",
    "     for idx in range(num_layers)]\n",
    ")\n",
    "\n",
    "W2 = tf.Variable(np.random.rand(state_size, num_classes),dtype=tf.float32)\n",
    "b2 = tf.Variable(np.zeros((1,num_classes)), dtype=tf.float32)\n",
    "\n",
    "# Unpack columns\n",
    "inputs_series = tf.split(batchX_placeholder, truncated_backprop_length, 1)\n",
    "labels_series = tf.unstack(batchY_placeholder, axis=1)\n",
    "\n",
    "# Forward passes\n",
    "# cell = tf.contrib.rnn.LSTMCell(state_size, state_is_tuple=True)\n",
    "cell = tf.contrib.rnn.MultiRNNCell([tf.contrib.rnn.LSTMCell(state_size,\n",
    "                                                            state_is_tuple=True) for _ in range(num_layers)], \n",
    "                                   state_is_tuple=True)\n",
    "states_series, current_state = tf.contrib.rnn.static_rnn(cell, inputs_series, initial_state=rnn_tuple_state)\n",
    "\n",
    "logits_series = [tf.matmul(state, W2) + b2 for state in states_series] #Broadcasted addition\n",
    "predictions_series = [tf.nn.softmax(logits) for logits in logits_series]\n",
    "\n",
    "losses = [tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=labels) for logits, labels in zip(logits_series,labels_series)]\n",
    "total_loss = tf.reduce_mean(losses)\n",
    "\n",
    "train_step = tf.train.AdagradOptimizer(0.3).minimize(total_loss)\n",
    "\n",
    "def plot(loss_list, predictions_series, batchX, batchY):\n",
    "    plt.subplot(2, 3, 1)\n",
    "    plt.cla()\n",
    "    plt.plot(loss_list)\n",
    "\n",
    "    for batch_series_idx in range(5):\n",
    "        one_hot_output_series = np.array(predictions_series)[:, batch_series_idx, :]\n",
    "        single_output_series = np.array([(1 if out[0] < 0.5 else 0) for out in one_hot_output_series])\n",
    "\n",
    "        plt.subplot(2, 3, batch_series_idx + 2)\n",
    "        plt.cla()\n",
    "        plt.axis([0, truncated_backprop_length, 0, 2])\n",
    "        left_offset = range(truncated_backprop_length)\n",
    "        plt.bar(left_offset, batchX[batch_series_idx, :], width=1, color=\"blue\")\n",
    "        plt.bar(left_offset, batchY[batch_series_idx, :] * 0.5, width=1, color=\"red\")\n",
    "        plt.bar(left_offset, single_output_series * 0.3, width=1, color=\"green\")\n",
    "\n",
    "    plt.draw()\n",
    "    plt.pause(0.0001)\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    plt.ion()\n",
    "    plt.figure()\n",
    "    plt.show()\n",
    "    loss_list = []\n",
    "\n",
    "    for epoch_idx in range(num_epochs):\n",
    "        x,y = generateData()\n",
    "\n",
    "        _current_state = np.zeros((num_layers, 2, batch_size, state_size))\n",
    "\n",
    "        print(\"New data, epoch\", epoch_idx)\n",
    "\n",
    "        for batch_idx in range(num_batches):\n",
    "            start_idx = batch_idx * truncated_backprop_length\n",
    "            end_idx = start_idx + truncated_backprop_length\n",
    "\n",
    "            batchX = x[:,start_idx:end_idx]\n",
    "            batchY = y[:,start_idx:end_idx]\n",
    "\n",
    "            _total_loss, _train_step, _current_state, _predictions_series = sess.run(\n",
    "                [total_loss, train_step, current_state, predictions_series],\n",
    "                feed_dict={\n",
    "                    batchX_placeholder: batchX,\n",
    "                    batchY_placeholder: batchY,\n",
    "                    init_state: _current_state\n",
    "                })\n",
    "\n",
    "\n",
    "            loss_list.append(_total_loss)\n",
    "\n",
    "            if batch_idx%100 == 0:\n",
    "                print(\"Step\",batch_idx, \"Batch loss\", _total_loss)\n",
    "                plot(loss_list, _predictions_series, batchX, batchY)\n",
    "\n",
    "plt.ioff()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
