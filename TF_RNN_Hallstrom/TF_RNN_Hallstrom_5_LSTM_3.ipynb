{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosave disabled\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%autosave 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to speed up the LSTM by not splitting up our inputs and labels into a list. To do this we remove the rows where `inputs_series` and `labels_series` are declared. Next we change the:\n",
    "\n",
    "`states_series, current_state = tf.nn.static_rnn(cell, inputs_series, initial_state=rnn_tuple_state)` \n",
    "\n",
    "line to become:\n",
    "\n",
    "`states_series, current_state = tf.nn.dynamic_rnn(cell, tf.expand_dims(batchX_placeholder, -1), initial_state=rnn_tuple_state)`\n",
    "`states_series = tf.reshape(states,series, [-1, state_size])`\n",
    "\n",
    "The `dynamic_rnn` function takes the batch inputs of shape `[batch_size, truncated_backprop_length, input_size]`, thus the addition of a single dimension on the end.\n",
    "\n",
    "Output will be the last state of every layer in the network as an LSTMStateTuple stored in `current_state` as well as a tensor `states_series` with the shape `[batch_size, truncated_backprop_length, state_size]` containing the hidden state of the last layer across all time-steps.\n",
    "\n",
    "The tensor `states_series` is reshaped on the second row in the code sample above to shape `[batch_size*truncated_backprop_length, state_size]`.\n",
    "\n",
    "format for `dynamic_rnn`:\n",
    "`tf.nn.dynamic_rnn(cell, inputs, sequence_length=None, initial_state=None, dtype=None, parallel_iterations=None, time_major=False, scope=None)`\n",
    "\n",
    "The `dynamic_rnn` function performs \"fully dynamic unrolling of inputs\".\n",
    "\n",
    "In `dynamic_rnn`, the input `inputs` is not a Python list of Tensors, one for each frame. Instead, `inputs` may be a single Tensor where the maximum time is either the first or second dimension (see the parameter `time_major`).\n",
    "\n",
    "Alternatively, it may be a (possibly nested) tuple of Tensors, each of them having matching batch and time dimensions. \n",
    "\n",
    "The corresponding output is either a single Tensor having the same number of time steps and batch size, or a (possibly nested) tuple of such tensors, matching the nested structure of `cell.output_size`.\n",
    "\n",
    "The parameter `sequence_length` is optional and is used to copy-through state and zero-out outputs when past a batch element's sequence length, so it is more for correctness than performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below the reshaping to the `state_series` we add the following two line:\n",
    "\n",
    "`logits = tf.matmul(states_series, W2) + b2` # Broadcasted addition\n",
    "`labels = tf.reshape(batchY_placeholder) [-1])`\n",
    "\n",
    "In TensorFlow reshaping, we read from the source tensor and \"write\" to the stination tensor with the last axis index changing fastest, and the first axis index changing slowest.\n",
    "\n",
    "Next calculate the predictions for the visualization:\n",
    "\n",
    "`logits_series = tf.unstack(tf.reshape(logits, [batch_size, truncated_backprop_length, num_classes]), axis=1)`\n",
    "`predictions_series = [tf.nn.softmax(logit) for logit in logits_list]`\n",
    "\n",
    "Here we actually split the tensors into lists again. Plot function is already expecting a list. The `sparse_softmax_cross_entropy_with_logits` can take the shape of our tensors!\n",
    "\n",
    "Modify the losses calculation to:\n",
    "\n",
    "`losses = tf.nn.sparse_softmax_cross_entropy_with_logits(logits, labels)`\n",
    "\n",
    "The logits must have the shape `[batch_size, num_classes]` and labels must have the shape `[batch_size]`. But now we are treating all time-steps as elements in our batch, so it will work out as we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-8-be1cf38c185b>:80: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2ddba75748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data, epoch 0\n",
      "Step 0 Batch loss 0.692443\n",
      "New data, epoch 1\n",
      "Step 0 Batch loss 0.697774\n",
      "New data, epoch 2\n",
      "Step 0 Batch loss 0.59338\n",
      "New data, epoch 3\n",
      "Step 0 Batch loss 0.61673\n",
      "New data, epoch 4\n",
      "Step 0 Batch loss 0.529\n",
      "New data, epoch 5\n",
      "Step 0 Batch loss 0.577213\n",
      "New data, epoch 6\n",
      "Step 0 Batch loss 0.397902\n",
      "New data, epoch 7\n",
      "Step 0 Batch loss 0.208848\n",
      "New data, epoch 8\n",
      "Step 0 Batch loss 0.332454\n",
      "New data, epoch 9\n",
      "Step 0 Batch loss 0.304072\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2ddb6e2ef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "num_epochs = 10 # originally 100\n",
    "total_series_length = 5000 # originally 50000\n",
    "truncated_backprop_length = 15\n",
    "state_size = 4\n",
    "num_classes = 2\n",
    "echo_step = 3\n",
    "batch_size = 5\n",
    "num_batches = total_series_length//batch_size//truncated_backprop_length\n",
    "num_layers = 3\n",
    "\n",
    "def generateData():\n",
    "    x = np.array(np.random.choice(2, total_series_length, p=[0.5, 0.5]))\n",
    "    y = np.roll(x, echo_step)\n",
    "    y[0:echo_step] = 0\n",
    "\n",
    "    x = x.reshape((batch_size, -1))  # The first index changing slowest, subseries as rows\n",
    "    y = y.reshape((batch_size, -1))\n",
    "\n",
    "    return (x, y)\n",
    "\n",
    "batchX_placeholder = tf.placeholder(tf.float32, [batch_size, truncated_backprop_length])\n",
    "batchY_placeholder = tf.placeholder(tf.int32, [batch_size, truncated_backprop_length])\n",
    "\n",
    "init_state = tf.placeholder(tf.float32, [num_layers, 2, batch_size, state_size])\n",
    "\n",
    "state_per_layer_list = tf.unstack(init_state, axis=0)\n",
    "rnn_tuple_state = tuple(\n",
    "    [tf.contrib.rnn.LSTMStateTuple(state_per_layer_list[idx][0], state_per_layer_list[idx][1])\n",
    "     for idx in range(num_layers)]\n",
    ")\n",
    "\n",
    "W2 = tf.Variable(np.random.rand(state_size, num_classes),dtype=tf.float32)\n",
    "b2 = tf.Variable(np.zeros((1,num_classes)), dtype=tf.float32)\n",
    "\n",
    "# Forward passes\n",
    "# cell = tf.contrib.rnn.LSTMCell(state_size, state_is_tuple=True)\n",
    "# Added \"reuse=True\" - JC\n",
    "cell = tf.contrib.rnn.MultiRNNCell([tf.contrib.rnn.LSTMCell(state_size, state_is_tuple=True,reuse=True) for _ in range(num_layers)], state_is_tuple=True)\n",
    "states_series, current_state = tf.nn.dynamic_rnn(cell, tf.expand_dims(batchX_placeholder, -1), initial_state=rnn_tuple_state)\n",
    "states_series = tf.reshape(states_series, [-1, state_size])\n",
    "\n",
    "logits = tf.matmul(states_series, W2) + b2 #Broadcasted addition\n",
    "labels = tf.reshape(batchY_placeholder, [-1])\n",
    "\n",
    "logits_series = tf.unstack(tf.reshape(logits, [batch_size, truncated_backprop_length, num_classes]), axis=1)\n",
    "predictions_series = [tf.nn.softmax(logit) for logit in logits_series]\n",
    "\n",
    "\n",
    "losses = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=labels)\n",
    "total_loss = tf.reduce_mean(losses)\n",
    "\n",
    "train_step = tf.train.AdagradOptimizer(0.3).minimize(total_loss)\n",
    "\n",
    "def plot(loss_list, predictions_series, batchX, batchY):\n",
    "    plt.subplot(2, 3, 1)\n",
    "    plt.cla()\n",
    "    plt.plot(loss_list)\n",
    "\n",
    "    for batch_series_idx in range(5):\n",
    "        one_hot_output_series = np.array(predictions_series)[:, batch_series_idx, :]\n",
    "        single_output_series = np.array([(1 if out[0] < 0.5 else 0) for out in one_hot_output_series])\n",
    "\n",
    "        plt.subplot(2, 3, batch_series_idx + 2)\n",
    "        plt.cla()\n",
    "        plt.axis([0, truncated_backprop_length, 0, 2])\n",
    "        left_offset = range(truncated_backprop_length)\n",
    "        plt.bar(left_offset, batchX[batch_series_idx, :], width=1, color=\"blue\")\n",
    "        plt.bar(left_offset, batchY[batch_series_idx, :] * 0.5, width=1, color=\"red\")\n",
    "        plt.bar(left_offset, single_output_series * 0.3, width=1, color=\"green\")\n",
    "\n",
    "    plt.draw()\n",
    "    plt.pause(0.0001)\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    plt.ion()\n",
    "    plt.figure()\n",
    "    plt.show()\n",
    "    loss_list = []\n",
    "\n",
    "    for epoch_idx in range(num_epochs):\n",
    "        x,y = generateData()\n",
    "\n",
    "        _current_state = np.zeros((num_layers, 2, batch_size, state_size))\n",
    "\n",
    "        print(\"New data, epoch\", epoch_idx)\n",
    "\n",
    "        for batch_idx in range(num_batches):\n",
    "            start_idx = batch_idx * truncated_backprop_length\n",
    "            end_idx = start_idx + truncated_backprop_length\n",
    "\n",
    "            batchX = x[:,start_idx:end_idx]\n",
    "            batchY = y[:,start_idx:end_idx]\n",
    "\n",
    "            _total_loss, _train_step, _current_state, _predictions_series = sess.run(\n",
    "                [total_loss, train_step, current_state, predictions_series],\n",
    "                feed_dict={\n",
    "                    batchX_placeholder: batchX,\n",
    "                    batchY_placeholder: batchY,\n",
    "                    init_state: _current_state\n",
    "                })\n",
    "\n",
    "\n",
    "            loss_list.append(_total_loss)\n",
    "\n",
    "            if batch_idx%100 == 0:\n",
    "                print(\"Step\",batch_idx, \"Batch loss\", _total_loss)\n",
    "                plot(loss_list, _predictions_series, batchX, batchY)\n",
    "\n",
    "plt.ioff()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
